{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "# custom modules\n",
    "from utils     import Options, rgb2gray\n",
    "from simulator import Simulator\n",
    "from model import ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from \\tmp\\tensorflow\\NeuralPlanner\\checkpoints\\save\\ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "# 0. initialization\n",
    "opt = Options()\n",
    "sim = Simulator(opt.map_ind, opt.cub_siz, opt.pob_siz, opt.act_num)\n",
    "\n",
    "NeuralPlanner = ConvNet(cub_siz=opt.cub_siz,pub_siz=opt.pob_siz,hist_len=opt.hist_len,logits_units=opt.act_num,\n",
    "                            num_filt1=opt.num_filt1,kernel_size1=opt.kernel_size1,num_filt2=opt.num_filt2,\n",
    "                            kernel_size2=opt.kernel_size2,pool_size=opt.pool_size,dense_units=opt.dense_units,dropout_rate=opt.dropout_rate)\n",
    "\n",
    "saver = tfe.Saver(NeuralPlanner.variables)\n",
    "saver.restore(tf.train.latest_checkpoint(opt.checkpoint_dir_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. initializations\n",
    "if opt.disp_on:\n",
    "    win_all = None\n",
    "    win_pob = None\n",
    "epi_step = 0    # #steps in current episode\n",
    "nepisodes = 0   # total #episodes executed\n",
    "nepisodes_solved = 0\n",
    "action = 0     # action to take given by the network\n",
    "\n",
    "# start a new game\n",
    "state = sim.newGame(opt.tgt_y, opt.tgt_x)\n",
    "full_state = np.zeros((opt.hist_len,opt.state_siz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 1. control loop\n",
    "for step in range(opt.eval_steps):\n",
    "    # check if episode ended\n",
    "    if state.terminal or epi_step >= opt.early_stop:\n",
    "        epi_step = 0\n",
    "        nepisodes += 1\n",
    "        if state.terminal:\n",
    "            nepisodes_solved += 1\n",
    "        # start a new game\n",
    "        state = sim.newGame(opt.tgt_y, opt.tgt_x)\n",
    "        full_state = np.zeros((opt.hist_len,opt.state_siz))\n",
    "    else:\n",
    "        full_state = np.append(full_state, rgb2gray(state.pob).reshape(1, opt.state_siz), 0)\n",
    "        if full_state.shape[0] > opt.hist_len: # remove the oldest history\n",
    "            full_state = np.delete(full_state, 0, 0)\n",
    "            \n",
    "        full_state_flat = np.asarray(full_state.reshape(1,opt.hist_len*opt.state_siz),dtype=np.float32)\n",
    "        full_state_flat = tf.data.Dataset.from_tensor_slices((full_state_flat,np.zeros((1,5))))\n",
    "        for image,label in tfe.Iterator(full_state_flat):\n",
    "            action = NeuralPlanner.predict(image,training=False)\n",
    "        action = np.argmax(action)\n",
    "        \n",
    "        state = sim.step(action)\n",
    "\n",
    "        epi_step += 1\n",
    "\n",
    "    if state.terminal or epi_step >= opt.early_stop:\n",
    "        epi_step = 0\n",
    "        nepisodes += 1\n",
    "        if state.terminal:\n",
    "            nepisodes_solved += 1\n",
    "        # start a new game\n",
    "        state = sim.newGame(opt.tgt_y, opt.tgt_x)\n",
    "\n",
    "    if step % opt.prog_freq == 0:\n",
    "        print(step)\n",
    "\n",
    "    if opt.disp_on:\n",
    "        if win_all is None:\n",
    "            plt.subplot(121)\n",
    "            win_all = plt.imshow(state.screen)\n",
    "            plt.subplot(122)\n",
    "            win_pob = plt.imshow(state.pob)\n",
    "        else:\n",
    "            win_all.set_data(state.screen)\n",
    "            win_pob.set_data(state.pob)\n",
    "        plt.pause(opt.disp_interval)\n",
    "        plt.draw()\n",
    "\n",
    "# 2. calculate statistics\n",
    "print(float(nepisodes_solved) / float(nepisodes))\n",
    "# 3. TODO perhaps  do some additional analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
